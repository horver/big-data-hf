{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTD2 notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Adat és módszer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feladatunk a terrorizmus tulajdonságainak kontintens- és országfüggőségének vizualizálása, valamint a terrorcselekmények klasszifikációja az áldozatok száma alapján.**\n",
    "\n",
    "GTD2 adatkészlet esetén terrorizmus az a cselekmény, melyre az alábbi pontok közül legalább kettő teljesül:\n",
    "1. Az erőszakos cselekedet célja egy politikai, gazdasági, vallási vagy társadalmi cél elérése volt.\n",
    "2. Az erőszakos cselekedet során egyértelmű volt a szándékos kényszerítés, megfélemlítés, vagy valamely más üzenet közvetítése egy nagyobb közönségnek, nem csak az áldozatoknak.\n",
    "3. Az erőszakos cselekedet során sérültek a nemzetközileg elismert emberi jogok.\n",
    "\n",
    "Az adatok 1970 és 2016 között történt terrorcselekményeket tartalmazzák. 1970-től 1997-ig rendszeresen frissítették, utána 2007-ig viszont visszamenőleg vitték fel az ismert támadásokat. Ezáltal valószínűleg ez az időszak nem adja vissza a teljes képet. 2007 után újra bekerültek az aktuális történések.\n",
    "\n",
    "A forrás részletes információkat tartalmaz az\n",
    "* esemény idejéről, hosszáról\n",
    "* incidensről (definíció szerinti értelmezése alapján)\n",
    "* incidens helyéről\n",
    "* támadásról (típusa, sikeressége)\n",
    "* fegyverről (típusa, altípusa)\n",
    "* célpontról/áldozatról (típusa, specifikussága, nemzeti jellege)\n",
    "* elkövetőről (csoport, létszám, bizonyosság) \n",
    "* veszteségekről és következményekről (halálos áldozatok száma, sérültek száma, anyagi kár, túszok)\n",
    "* egyéb információkról és forrásokról"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Adatok beolvasása\n",
    "\n",
    "Spark python könyvtár importálása, majd a spark környezet `sc` létrehozása lokál módban."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sc = SparkContext('local', 'gtd2')\n",
    "sqlc = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az adatokat `gtd.txt` tabulátorral elválasztott szöveges fájlból olvassuk ki. Majd egy `map` segítségével tagoljuk a tabulátor alapján az oszlopokat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = sc.textFile(\"gtd.txt\")\n",
    "data = raw.map(lambda x: x.split('\\t'))\n",
    "\n",
    "# Segéd függvény, amely az adatnak az oszlop indexét adja vissza az oszlopnév alapján\n",
    "def getIndexByKey(key):\n",
    "    return data.take(1)[0].index(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Terrorcselekmények számának év szerinti összesítése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iyear = getIndexByKey('iyear')\n",
    "rdd_years = data.map(lambda x: (x[iyear], 1))\\\n",
    "                .reduceByKey(lambda a, b: a+b)\\\n",
    "                .filter(lambda x: x[0]!='iyear')\\\n",
    "                .sortByKey(1)\n",
    "\n",
    "years = rdd_years.collect()\n",
    "df_years = pd.DataFrame.from_records(years, columns = ('year', 'count')).apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `df_years` tartalmazza az egyes években összesített terrorcselekmények számát. A `df_years_kill` változóban pedig az összes haláleset található évekre lebontva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nkill = getIndexByKey('nkill')\n",
    "rdd_years_kills = data.map(lambda x: (x[iyear], x[nkill]))\\\n",
    "                      .filter(lambda x: x[0]!='iyear')\\\n",
    "                      .sortByKey(1)\n",
    "        \n",
    "df_years_kill = pd.DataFrame.from_records(rdd_years_kills.collect(), columns = ('year', 'killed')).apply(pd.to_numeric)\n",
    "df_years_kill = df_years_kill.groupby('year')\\\n",
    "                             .sum()\\\n",
    "                             .reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statisztikai adatok számításához lesz rá szükség. TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "import numpy as np\n",
    "summary_year = Statistics.colStats(rdd_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('46 év alatt átlagosan ennyi haláleset történt: ', df_years_kill['killed'].mean())\n",
    "print(int(df_years_kill.max()['year']),'-ban/-ben történt a legtöbb (',int(df_years_kill.max()['killed']),') haláleset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Terrorcselekmények az országokban\n",
    "#### 2.3.1 Incidensek száma az országokban\n",
    "Az `incidents_in_countries`-ban találhatóak az összes terrorcselekmény száma országokra bontva. Az első öt legtöbb terrorcselekményt tartalmazó ország megjelenítése."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "country_txt = getIndexByKey('country_txt')\n",
    "incidents_in_countries = data.map(lambda x: (x[country_txt], 1)).reduceByKey(lambda a,b: a+b)\n",
    "incidents_in_countries = incidents_in_countries.map(lambda x: (x[1], x[0])).sortByKey(0)\n",
    "incidents_in_countries.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Halálesetek száma az egyes országokban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "country = getIndexByKey('country_txt')\n",
    "nkill = getIndexByKey('nkill')\n",
    "\n",
    "rdd_country_kill = data.map(lambda x: (x[country], x[nkill]))\\\n",
    "                       .filter(lambda x: x[0]!='country_txt')\\\n",
    "                       .sortByKey(1)\n",
    "\n",
    "country_kill = rdd_country_kill.collect()\n",
    "df_country_kill = pd.DataFrame.from_records(country_kill, columns = ('country', 'killed'))\n",
    "df_country_kill['killed'] = df_country_kill['killed'].apply(pd.to_numeric)\n",
    "df_country_kill = df_country_kill.groupby('country').sum().reset_index()\n",
    "df_country_kill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Halálesetek száma régiókra vetítve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "region = getIndexByKey('region')\n",
    "nkill = getIndexByKey('nkill')\n",
    "rdd_region_kill = data.map(lambda x: (x[region], x[nkill]))\\\n",
    "                      .filter(lambda x: x[0]!='region')\\\n",
    "                      .sortByKey(1)\n",
    "\n",
    "region_kill = rdd_region_kill.collect()\n",
    "df_region_kill = pd.DataFrame.from_records(region_kill, columns = ('region', 'killed')).apply(pd.to_numeric)\n",
    "#df_region_kill['killed'] = df_region_kill['killed'].apply(pd.to_numeric)\n",
    "df_region_kill = df_region_kill.groupby('region').sum().reset_index()\n",
    "df_region_kill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vizualizációk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Terrorcselekmények időbeli trendje\n",
    "Az alábbi vizualizációs blokk egy egyszerű idősor diagram, amely ábrázolja, hogy egy évben mennyi terrorcselekmény történt, és az évek során hány halálos áldozat volt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "m, b = np.polyfit(df_years['year'], df_years['count'], 1)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "pl1 = fig.add_subplot(211)\n",
    "pl1.set_ylabel('Terrorcselekmények száma')\n",
    "pl1.set_title('Halálesetek és terrorcselekmények száma 1970-2016')\n",
    "plt.yscale('linear')\n",
    "pl1.plot(df_years['year'], df_years['count'])\n",
    "pl1.plot(df_years['year'], m*df_years['year']+b, '-')\n",
    "\n",
    "pl2= fig.add_subplot(212)\n",
    "pl2.set_ylabel('Halálesetek száma')\n",
    "pl2.set_xlabel('years')\n",
    "plt.yscale('log')\n",
    "pl2.plot(df_years_kill['year'], df_years_kill['killed'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3.2 Terrortámadások denzitása\n",
    "\n",
    "Az alábbi vizualizációs blokk az összes terrorcselekményt ábrázolja a hosszúsági és szélességi adatok alapján.\n",
    "A vizualizációhoz elsősorban a *datashader* könyvtárat használjuk. A codebook alapján, a hosszúsági és szélességi adatok WGS84-es formátumba vannak tárolva, viszont ahhoz, hogy megfelelően tudjuk ábrázolni a pontokat, WebMercator formátumba kell  projektálni a meglévő hosszúsági és szélességi adatokat. Ehhez a *pyproj* nevű könyvtárat használjuk. Ehhez egy-egy  függvényt (*toWebMLon* és *toWebMLat*) definiáltunk, ami megvalósítja a megfelelő projekciókat. A pozíciókat a *pandas* könyvtár segítségével egy dataframe-be tároljuk, amit feltudunk használni a vizualizációhoz. Az ábrán fekete alapra egy \n",
    "\"hőtérkép\"-hez hasonló eredményt várunk, vagyis adott térségben lévő színfoltok fogják jellemezni a terror cselekmények helybeli sűrűségét.\n",
    "\n",
    "Később a *datashader* könyvtárat arra fogjuk használni, hogy kontinensekre, ill. országokra vetítve ábrázoljuk a terrorcselekmények számát. Minél több terrortámadás történt egy kontinensen vagy egy országban, az annál világosabb színt kap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Proj, transform\n",
    "import pandas as pd\n",
    "\n",
    "# long/lat. adatok Web mercator formátumba konvertálásához\n",
    "def toWebMLon(lon):\n",
    "    loc = transform(Proj(init='epsg:4326'), Proj(init='epsg:3857'), lon, 0)\n",
    "    return loc[0]\n",
    "\n",
    "def toWebMLat(lat):\n",
    "    loc = transform(Proj(init='epsg:4326'), Proj(init='epsg:3857'), 0, lat)\n",
    "    return loc[1]\n",
    "\n",
    "# indexek\n",
    "longitude = getIndexByKey('longitude')\n",
    "latitude = getIndexByKey('latitude')\n",
    "successful = getIndexByKey('success')\n",
    "attack_type = getIndexByKey('attacktype1')\n",
    "weapon_type = getIndexByKey('weaptype1_txt')\n",
    "\n",
    "points = data.map(lambda x: (x[longitude], x[latitude], x[successful], x[attack_type], x[weapon_type]))\\\n",
    "             .filter(lambda x: x[0]!='longitude')\\\n",
    "             .collect()\n",
    "\n",
    "locations = pd.DataFrame.from_records(points, columns = ['longitude', 'latitude', 'success', 'attack', 'weapon']).replace({',': '.'}, regex=True)\n",
    "locations['longitude'] = locations['longitude'].apply(pd.to_numeric)\n",
    "locations['latitude'] = locations['latitude'].apply(pd.to_numeric)\n",
    "\n",
    "locations['longitude'] = locations['longitude'].apply(toWebMLon)\n",
    "locations['latitude'] = locations['latitude'].apply(toWebMLat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "import datashader.glyphs\n",
    "import datashader.transfer_functions as tf\n",
    "from functools import partial\n",
    "from datashader.utils import export_image\n",
    "from matplotlib.cm import hot\n",
    "\n",
    "background = \"black\"\n",
    "export = partial(export_image, background = background, export_path=\"export\")\n",
    "\n",
    "x_range = (locations['longitude'].min(), locations['longitude'].max())\n",
    "y_range = (locations['latitude'].min(), locations['latitude'].max())\n",
    "\n",
    "plot_width  = int(1500) # Minél nagyobb, annál jobb a felbontás, akár országon belüli eloszlás vizsgálatához\n",
    "plot_height = int(plot_width*7.0/12)\n",
    "\n",
    "# Terrorcselekmények denzitása\n",
    "cvs = ds.Canvas(plot_width=plot_width, plot_height=plot_height, x_range=x_range, y_range=y_range)\n",
    "agg = cvs.points(locations, 'longitude', 'latitude') \n",
    "export(tf.shade(agg, cmap = hot, how='eq_hist'), \"gtd_on_map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if background == \"black\":\n",
    "      color_key = {'1':'red', '0':'green'}\n",
    "else: color_key = {'1':'red', '0':'green'}\n",
    "\n",
    "cvs = ds.Canvas(plot_width=plot_width, plot_height=plot_height, x_range=x_range, y_range=y_range)\n",
    "agg = cvs.points(locations, 'longitude', 'latitude', ds.count_cat('weapon'))\n",
    "\n",
    "export(tf.shade(agg, color_key=color_key, how='eq_hist'), \"successful attacks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Terrorcselekmények kontines és országfüggősége\n",
    "\n",
    "A terrorcselekmények számát régiókra összesítettük a `df_region_kill` dataframe-ben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "Z = linkage(df_region_kill, 'average')\n",
    "\n",
    "plt.title('Régiók klaszterezése')\n",
    "plt.xlabel('Régiók')\n",
    "plt.ylabel('Távolság')\n",
    "dendrogram(Z, leaf_rotation=90)\n",
    "plt.show()\n",
    "\n",
    "c, coph_dists = cophenet(Z, pdist(df_region_kill))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Klasszifikáció  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasszifikálnunk kell az incidenseket az áldozatok száma alapján. Alkothatnánk például 4 osztályt a percentilisek alapján. Ne nekünk kelljen megmondani, hogy 10 alatt kevésnek számít, 100 felett meg soknak. Beszéljenek a számok! Ha pl az adatkészlet alapján az esetek 25%-ában kevesebben haltak meg 20-nál, 20 legyen a legkevesebb áldozatot jelölő osztály."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "nkill_column = data.map(lambda x: [x[nkill]]).filter(lambda x: x[0]!='nkill' and x[0]!='')\n",
    "df = pd.DataFrame(nkill_column.collect(),columns=['nkill']).apply(pd.to_numeric)\n",
    "df.quantile([0.25,0.5,0.75,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vajon hogyan alakul az áldozatok száma az összes incidens esetén?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nkill_sum = data.map(lambda x: (x[nkill], 1)).filter(lambda x: x[0]!='nkill' and x[0]!='').reduceByKey(lambda a,b: a+b).sortByKey(1)\n",
    "df2 = pd.DataFrame(nkill_sum.collect(), columns=['nkills','sum']).apply(pd.to_numeric)\n",
    "\n",
    "plt.plot(df2['nkills'], df2['sum'], '.')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df2['nkills'], df2['sum'])\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getClassLabel(number):\n",
    "    borders = (1,5,10,100) # i. oszályba tartozik egy incidens, ha a tömb i. indexű eleménél kevesebb áldozata volt\n",
    "    for i in range(len(borders)):\n",
    "        if int(number)<borders[i]:\n",
    "            return i\n",
    "    return len(borders)\n",
    "\n",
    "nkill_classes = data.map(lambda x: x[nkill]).filter(lambda x: x!='nkill' and x!='').map(lambda x: (getClassLabel(x), 1)).reduceByKey(lambda a,b: a+b).sortByKey(1)\n",
    "nkill_classes.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alább egy demó látható a döntési fás tanításból."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "# a tulajdonságok\n",
    "iyear = getIndexByKey('iyear')\n",
    "imonth = getIndexByKey('imonth')\n",
    "iday = getIndexByKey('iday')\n",
    "extended = getIndexByKey('extended')\n",
    "country = getIndexByKey('country')\n",
    "region = getIndexByKey('region')\n",
    "specificity = getIndexByKey('specificity')\n",
    "vicinity = getIndexByKey('vicinity')\n",
    "crit1 = getIndexByKey('crit1')\n",
    "crit2 = getIndexByKey('crit2')\n",
    "crit3 = getIndexByKey('crit3')\n",
    "doubtterr = getIndexByKey('doubtterr')\n",
    "alternative = getIndexByKey('alternative')\n",
    "multiple = getIndexByKey('multiple')\n",
    "success = getIndexByKey('success')\n",
    "suicide = getIndexByKey('suicide')\n",
    "attacktype1 = getIndexByKey('attacktype1')\n",
    "attacktype2 = getIndexByKey('attacktype2')\n",
    "attacktype3 = getIndexByKey('attacktype3')\n",
    "targtype1 = getIndexByKey('targtype1')\n",
    "targsubtype1 = getIndexByKey('targsubtype1')\n",
    "natlty1 = getIndexByKey('natlty1')\n",
    "targtype2 = getIndexByKey('targtype2')\n",
    "targsubtype2 = getIndexByKey('targsubtype2')\n",
    "natlty2 = getIndexByKey('natlty2')\n",
    "targtype3 = getIndexByKey('targtype3')\n",
    "targsubtype3 = getIndexByKey('targsubtype3')\n",
    "natlty3 = getIndexByKey('natlty3')\n",
    "guncertain1 = getIndexByKey('guncertain1')\n",
    "guncertain2 = getIndexByKey('guncertain2')\n",
    "guncertain3 = getIndexByKey('guncertain3')\n",
    "individual = getIndexByKey('individual')\n",
    "nperps = getIndexByKey('nperps')\n",
    "claimed = getIndexByKey('claimed')\n",
    "claimmode = getIndexByKey('claimmode')\n",
    "claim2 = getIndexByKey('claim2')\n",
    "claimmode2 = getIndexByKey('claimmode2')\n",
    "claim3 = getIndexByKey('claim3')\n",
    "claimmode3 = getIndexByKey('claimmode3')\n",
    "compclaim = getIndexByKey('compclaim')\n",
    "weaptype1 = getIndexByKey('weaptype1')\n",
    "weapsubtype1 = getIndexByKey('weapsubtype1')\n",
    "weaptype2 = getIndexByKey('weaptype2')\n",
    "weapsubtype2 = getIndexByKey('weapsubtype2')\n",
    "weaptype3 = getIndexByKey('weaptype3')\n",
    "weapsubtype3 = getIndexByKey('weapsubtype3')\n",
    "weaptype4 = getIndexByKey('weaptype4')\n",
    "weapsubtype4 = getIndexByKey('weapsubtype4')\n",
    "nwound = getIndexByKey('nwound')\n",
    "nwoundte = getIndexByKey('nwoundte')\n",
    "proper = getIndexByKey('property')\n",
    "propextent = getIndexByKey('propextent')\n",
    "ishostkid = getIndexByKey('ishostkid')\n",
    "nhostkid = getIndexByKey('nhostkid')\n",
    "ndays = getIndexByKey('ndays')\n",
    "ransom = getIndexByKey('ransom')\n",
    "hostkidoutcome = getIndexByKey('hostkidoutcome')\n",
    "nreleased = getIndexByKey('nreleased')\n",
    "INT_LOG = getIndexByKey('INT_LOG')\n",
    "INT_IDEO = getIndexByKey('INT_IDEO')\n",
    "INT_MISC = getIndexByKey('INT_MISC')\n",
    "INT_ANY = getIndexByKey('INT_ANY')\n",
    "\n",
    "# kezdeti szűrés\n",
    "data_filtered = data.map(lambda x: np.array(x))\\\n",
    "                    .filter(lambda x: x[nkill]!='nkill' and x[nkill]!='' and x[iyear]!='' and x[imonth]!=''\n",
    "                            and x[iday]!='' and x[extended]!='' and x[country]!='' and x[region]!='' \n",
    "                            and x[specificity]!='' and x[vicinity]!='' and x[crit1]!='' and x[crit2]!=''\n",
    "                            and x[crit3]!='' and x[doubtterr]!='' and x[multiple]!='' and x[success]!='' \n",
    "                            and x[suicide]!='' and x[attacktype1]!='' and x[targtype1]!='' and x[natlty1]!='' \n",
    "                            and x[guncertain1]!='' and x[individual]!='' and x[weaptype1]!='' and x[proper]!='' \n",
    "                            and x[ishostkid]!='' and x[ransom]!='')\n",
    "\n",
    "# az új adathalmazunk, címkékkel együtt, tanításhoz (LabeledPoint)\n",
    "data_rdd_of_labeledpoints = data_filtered.map(lambda x: LabeledPoint(getClassLabel(x[nkill]), x[[iyear, imonth, iday, extended, country,\n",
    "                                              region, specificity, vicinity, crit1, crit2, crit3, doubtterr, multiple, \n",
    "                                              success, suicide, attacktype1, targtype1, natlty1, guncertain1, individual, \n",
    "                                              weaptype1, proper, ishostkid, ransom, INT_LOG, INT_IDEO, INT_MISC, INT_ANY]]))\n",
    "\n",
    "# a PCA-hoz az adathalmaz, vektorokként\n",
    "data_of_vectors = data_rdd_of_labeledpoints.map(lambda x: x.features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "\n",
    "mat = RowMatrix(data_of_vectors)\n",
    "# Compute the top 4 principal components.\n",
    "# Principal components are stored in a local dense matrix.\n",
    "pc = mat.computePrincipalComponents(4)\n",
    "\n",
    "# Project the rows to the linear space spanned by the top 4 principal components.\n",
    "projected = mat.multiply(pc).rows.collect()\n",
    "pc.toArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A döntési fa tanítása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = data_rdd_of_labeledpoints.randomSplit([0.8, 0.2])\n",
    "\n",
    "# 3:2, 9:2, 10:2, 11:2, 14:2, 15:2\n",
    "\n",
    "model = DecisionTree.trainClassifier(trainingData, numClasses=5, categoricalFeaturesInfo={},\n",
    "                                     impurity='gini', maxDepth=5, maxBins=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Modell értékelése, pontosság, hibaarány számítása\n",
    "predictions = model.predict(testData.map(lambda x: x.features))\n",
    "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(\n",
    "    lambda lp: lp[0] != lp[1]).count() / float(testData.count())\n",
    "print('Test Error = ' + str(testErr))\n",
    "print('Learned classification tree model:')\n",
    "print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
